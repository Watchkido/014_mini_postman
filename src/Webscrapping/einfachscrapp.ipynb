{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc577e6",
   "metadata": {},
   "source": [
    "# Hockey Statistics Scraper\n",
    "Dieses Notebook zeigt, wie man Hockey-Statistiken von einer Website scrapt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfd58297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Alle Bibliotheken erfolgreich importiert!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"‚úÖ Alle Bibliotheken erfolgreich importiert!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1094b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_hockey_table(url_or_html):\n",
    "    \"\"\"\n",
    "    Scrapt Hockey-Statistiken aus einer HTML-Tabelle\n",
    "    \n",
    "    Args:\n",
    "        url_or_html (str): URL der Webseite oder HTML-String\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Gescrapte Team-Daten\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Content laden (URL oder HTML-String)\n",
    "    if url_or_html.startswith('http'):\n",
    "        # Von URL laden\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "        response = requests.get(url_or_html, headers=headers)\n",
    "        html_content = response.content\n",
    "    else:\n",
    "        # Direkter HTML-String\n",
    "        html_content = url_or_html\n",
    "    \n",
    "    # 2. HTML parsen\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    table = soup.find('table', class_='table')\n",
    "    \n",
    "    if not table:\n",
    "        raise ValueError(\"‚ùå Keine Tabelle mit class='table' gefunden!\")\n",
    "    \n",
    "    # 3. Header extrahieren\n",
    "    headers = [th.get_text().strip() for th in table.find('tr').find_all('th')]\n",
    "    \n",
    "    # 4. Team-Daten extrahieren (class=\"team\")\n",
    "    data_rows = []\n",
    "    for row in table.find_all('tr', class_='team'):\n",
    "        row_data = [td.get_text().strip() or None for td in row.find_all('td')]\n",
    "        data_rows.append(row_data)\n",
    "    \n",
    "    # 5. DataFrame erstellen und numerische Spalten konvertieren\n",
    "    df = pd.DataFrame(data_rows, columns=headers)\n",
    "    \n",
    "    # 6. Numerische Spalten konvertieren\n",
    "    numeric_cols = ['Year', 'Wins', 'Losses', 'Goals For (GF)', 'Goals Against (GA)', 'Win %', '+ / -']\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    print(f\"‚úÖ {len(df)} Teams erfolgreich gescrapt!\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e56f81f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Scrape URL: https://www.scrapethissite.com/pages/forms/?page_num=1\n",
      "‚úÖ 25 Teams erfolgreich gescrapt!\n",
      "\n",
      "üìä Erste 5 Teams:\n",
      "            Team Name  Year  Wins  Losses OT Losses  Win %  Goals For (GF)  \\\n",
      "0       Boston Bruins  1990    44      24      None  0.550             299   \n",
      "1      Buffalo Sabres  1990    31      30      None  0.388             292   \n",
      "2      Calgary Flames  1990    46      26      None  0.575             344   \n",
      "3  Chicago Blackhawks  1990    49      23      None  0.613             284   \n",
      "4   Detroit Red Wings  1990    34      38      None  0.425             273   \n",
      "\n",
      "   Goals Against (GA)  + / -  \n",
      "0                 264     35  \n",
      "1                 278     14  \n",
      "2                 263     81  \n",
      "3                 211     73  \n",
      "4                 298    -25  \n",
      "‚úÖ 25 Teams erfolgreich gescrapt!\n",
      "\n",
      "üìä Erste 5 Teams:\n",
      "            Team Name  Year  Wins  Losses OT Losses  Win %  Goals For (GF)  \\\n",
      "0       Boston Bruins  1990    44      24      None  0.550             299   \n",
      "1      Buffalo Sabres  1990    31      30      None  0.388             292   \n",
      "2      Calgary Flames  1990    46      26      None  0.575             344   \n",
      "3  Chicago Blackhawks  1990    49      23      None  0.613             284   \n",
      "4   Detroit Red Wings  1990    34      38      None  0.425             273   \n",
      "\n",
      "   Goals Against (GA)  + / -  \n",
      "0                 264     35  \n",
      "1                 278     14  \n",
      "2                 263     81  \n",
      "3                 211     73  \n",
      "4                 298    -25  \n"
     ]
    }
   ],
   "source": [
    "# Test mit echter URL (erste Seite)\n",
    "url = \"https://www.scrapethissite.com/pages/forms/?page_num=1\"\n",
    "print(f\"üîç Scrape URL: {url}\")\n",
    "\n",
    "try:\n",
    "    df = scrape_hockey_table(url)\n",
    "    print(f\"\\nüìä Erste 5 Teams:\")\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Fehler: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "caac66e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Test mit HTML-String:\n",
      "‚úÖ 1 Teams erfolgreich gescrapt!\n",
      "       Team Name  Year  Wins  Losses OT Losses  Win %  Goals For (GF)  \\\n",
      "0  Boston Bruins  1990    44      24      None   0.55             299   \n",
      "\n",
      "   Goals Against (GA)  + / -  \n",
      "0                 264     35  \n"
     ]
    }
   ],
   "source": [
    "# Test mit HTML-String (Beispiel)\n",
    "html_string = '''\n",
    "<table class=\"table\">\n",
    "<tbody>\n",
    "<tr>\n",
    "    <th>Team Name</th>\n",
    "    <th>Year</th>\n",
    "    <th>Wins</th>\n",
    "    <th>Losses</th>\n",
    "    <th>OT Losses</th>\n",
    "    <th>Win %</th>\n",
    "    <th>Goals For (GF)</th>\n",
    "    <th>Goals Against (GA)</th>\n",
    "    <th>+ / -</th>\n",
    "</tr>\n",
    "<tr class=\"team\">\n",
    "    <td class=\"name\">Boston Bruins</td>\n",
    "    <td class=\"year\">1990</td>\n",
    "    <td class=\"wins\">44</td>\n",
    "    <td class=\"losses\">24</td>\n",
    "    <td class=\"ot-losses\"></td>\n",
    "    <td class=\"pct text-success\">0.55</td>\n",
    "    <td class=\"gf\">299</td>\n",
    "    <td class=\"ga\">264</td>\n",
    "    <td class=\"diff text-success\">35</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "'''\n",
    "\n",
    "print(\"üß™ Test mit HTML-String:\")\n",
    "df_html = scrape_hockey_table(html_string)\n",
    "print(df_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "baec139c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Daten gespeichert als: hockey_data_20251013_161533.csv\n",
      "\n",
      "üìà STATISTIKEN:\n",
      "Anzahl Teams: 25\n",
      "Jahre: 1990 - 1991\n",
      "Verschiedene Teams: 21\n"
     ]
    }
   ],
   "source": [
    "# Daten speichern (wenn vorhanden)\n",
    "if 'df' in locals() and not df.empty:\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f'hockey_data_{timestamp}.csv'\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"üíæ Daten gespeichert als: {filename}\")\n",
    "    \n",
    "    # Statistiken anzeigen\n",
    "    print(f\"\\nüìà STATISTIKEN:\")\n",
    "    print(f\"Anzahl Teams: {len(df)}\")\n",
    "    if 'Year' in df.columns:\n",
    "        print(f\"Jahre: {df['Year'].min()} - {df['Year'].max()}\")\n",
    "    if 'Team Name' in df.columns:\n",
    "        print(f\"Verschiedene Teams: {df['Team Name'].nunique()}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Kein DataFrame zum Speichern verf√ºgbar. F√ºhren Sie zuerst die Scraping-Zellen aus!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d1e6ae",
   "metadata": {},
   "source": [
    "## Multi-Page Scraping\n",
    "Scrape alle Seiten der Hockey-Statistiken (1-24 Seiten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66c8aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_hockey_pages(max_pages=24, delay=1.5):\n",
    "    \"\"\"\n",
    "    Scrapt alle Seiten der Hockey-Statistiken\n",
    "    \n",
    "    Args:\n",
    "        max_pages (int): Maximale Anzahl Seiten (Standard: 24)\n",
    "        delay (float): Verz√∂gerung zwischen Requests in Sekunden\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Alle gescrapten Team-Daten\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"üöÄ Scrape {max_pages} Seiten Hockey-Daten...\")\n",
    "    all_data = []\n",
    "    headers_list = []\n",
    "    \n",
    "    for page in range(1, max_pages + 1):\n",
    "        url = f\"https://www.scrapethissite.com/pages/forms/?page_num={page}\"\n",
    "        print(f\"üì° Seite {page}/{max_pages}\")\n",
    "        \n",
    "        try:\n",
    "            # Request senden\n",
    "            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # HTML parsen\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            table = soup.find('table', class_='table')\n",
    "            \n",
    "            if table:\n",
    "                # Header (nur bei Seite 1)\n",
    "                if page == 1:\n",
    "                    headers_list = [th.get_text().strip() for th in table.find('tr').find_all('th')]\n",
    "                \n",
    "                # Team-Daten extrahieren\n",
    "                team_rows = table.find_all('tr', class_='team')\n",
    "                \n",
    "                for row in team_rows:\n",
    "                    row_data = [td.get_text().strip() or None for td in row.find_all('td')]\n",
    "                    if len(row_data) == len(headers_list):\n",
    "                        all_data.append(row_data)\n",
    "                \n",
    "                print(f\"   ‚úÖ {len(team_rows)} Teams\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è  Keine Tabelle\")\n",
    "            \n",
    "            # H√∂fliche Verz√∂gerung\n",
    "            if page < max_pages:\n",
    "                time.sleep(delay)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Fehler: {e}\")\n",
    "    \n",
    "    # DataFrame erstellen\n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data, columns=headers_list)\n",
    "        \n",
    "        # Datentypen optimieren\n",
    "        numeric_cols = ['Year', 'Wins', 'Losses', 'Goals For (GF)', 'Goals Against (GA)', '+ / -']\n",
    "        for col in numeric_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "        if 'Win %' in df.columns:\n",
    "            df['Win %'] = pd.to_numeric(df['Win %'], errors='coerce')\n",
    "        \n",
    "        print(f\"‚úÖ Gesamt: {len(df)} Teams von {max_pages} Seiten gescrapt!\")\n",
    "        return df\n",
    "    else:\n",
    "        print(\"‚ùå Keine Daten gefunden!\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81b0670d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Test mit nur 3 Seiten:\n",
      "üöÄ Scrape 24 Seiten Hockey-Daten...\n",
      "üì° Seite 1/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 2/24\n",
      "üì° Seite 2/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 3/24\n",
      "üì° Seite 3/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 4/24\n",
      "üì° Seite 4/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 5/24\n",
      "üì° Seite 5/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 6/24\n",
      "üì° Seite 6/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 7/24\n",
      "üì° Seite 7/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 8/24\n",
      "üì° Seite 8/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 9/24\n",
      "üì° Seite 9/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 10/24\n",
      "üì° Seite 10/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 11/24\n",
      "üì° Seite 11/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 12/24\n",
      "üì° Seite 12/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 13/24\n",
      "üì° Seite 13/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 14/24\n",
      "üì° Seite 14/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 15/24\n",
      "üì° Seite 15/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 16/24\n",
      "üì° Seite 16/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 17/24\n",
      "üì° Seite 17/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 18/24\n",
      "üì° Seite 18/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 19/24\n",
      "üì° Seite 19/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 20/24\n",
      "üì° Seite 20/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 21/24\n",
      "üì° Seite 21/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 22/24\n",
      "üì° Seite 22/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 23/24\n",
      "üì° Seite 23/24\n",
      "   ‚úÖ 25 Teams\n",
      "   ‚úÖ 25 Teams\n",
      "üì° Seite 24/24\n",
      "üì° Seite 24/24\n",
      "   ‚úÖ 7 Teams\n",
      "‚úÖ Gesamt: 582 Teams von 24 Seiten gescrapt!\n",
      "\n",
      "üìä ERGEBNISSE:\n",
      "Teams gesamt: 582\n",
      "Jahre: 1990 - 2011\n",
      "Verschiedene Teams: 35\n",
      "\n",
      "üèÜ TOP 5 TEAMS (meiste Siege):\n",
      "               Team Name  Year  Wins  Losses\n",
      "126    Detroit Red Wings  1995    62      13\n",
      "382    Detroit Red Wings  2005    58      16\n",
      "58   Pittsburgh Penguins  1992    56      21\n",
      "442    Detroit Red Wings  2007    54      21\n",
      "521  Washington Capitals  2009    54      15\n",
      "   ‚úÖ 7 Teams\n",
      "‚úÖ Gesamt: 582 Teams von 24 Seiten gescrapt!\n",
      "\n",
      "üìä ERGEBNISSE:\n",
      "Teams gesamt: 582\n",
      "Jahre: 1990 - 2011\n",
      "Verschiedene Teams: 35\n",
      "\n",
      "üèÜ TOP 5 TEAMS (meiste Siege):\n",
      "               Team Name  Year  Wins  Losses\n",
      "126    Detroit Red Wings  1995    62      13\n",
      "382    Detroit Red Wings  2005    58      16\n",
      "58   Pittsburgh Penguins  1992    56      21\n",
      "442    Detroit Red Wings  2007    54      21\n",
      "521  Washington Capitals  2009    54      15\n"
     ]
    }
   ],
   "source": [
    "# Beispiel: Scrape nur die ersten 3 Seiten (zum Testen)\n",
    "print(\"üß™ Test mit nur 3 Seiten:\")\n",
    "df_multi = scrape_all_hockey_pages(max_pages=24, delay=1.0)\n",
    "\n",
    "if not df_multi.empty:\n",
    "    print(f\"\\nüìä ERGEBNISSE:\")\n",
    "    print(f\"Teams gesamt: {len(df_multi)}\")\n",
    "    print(f\"Jahre: {df_multi['Year'].min()} - {df_multi['Year'].max()}\")\n",
    "    print(f\"Verschiedene Teams: {df_multi['Team Name'].nunique()}\")\n",
    "    \n",
    "    print(f\"\\nüèÜ TOP 5 TEAMS (meiste Siege):\")\n",
    "    top5 = df_multi.nlargest(5, 'Wins')[['Team Name', 'Year', 'Wins', 'Losses']]\n",
    "    print(top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96ba5245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Die ersten 10 Teams aus allen Seiten:\n",
      "               Team Name  Year  Wins  Losses OT Losses  Win %  Goals For (GF)  \\\n",
      "0          Boston Bruins  1990    44      24      None  0.550             299   \n",
      "1         Buffalo Sabres  1990    31      30      None  0.388             292   \n",
      "2         Calgary Flames  1990    46      26      None  0.575             344   \n",
      "3     Chicago Blackhawks  1990    49      23      None  0.613             284   \n",
      "4      Detroit Red Wings  1990    34      38      None  0.425             273   \n",
      "5        Edmonton Oilers  1990    37      37      None  0.463             272   \n",
      "6       Hartford Whalers  1990    31      38      None  0.388             238   \n",
      "7      Los Angeles Kings  1990    46      24      None  0.575             340   \n",
      "8  Minnesota North Stars  1990    27      39      None  0.338             256   \n",
      "9     Montreal Canadiens  1990    39      30      None  0.487             273   \n",
      "\n",
      "   Goals Against (GA)  + / -  \n",
      "0                 264     35  \n",
      "1                 278     14  \n",
      "2                 263     81  \n",
      "3                 211     73  \n",
      "4                 298    -25  \n",
      "5                 272      0  \n",
      "6                 276    -38  \n",
      "7                 254     86  \n",
      "8                 266    -10  \n",
      "9                 249     24  \n"
     ]
    }
   ],
   "source": [
    "# Hier kannst du eigenen Code erg√§nzen oder weitere Tests durchf√ºhren\n",
    "# Beispiel: Zeige die ersten 10 Teams aus dem Multi-Page-Scraping\n",
    "if 'df_multi' in locals() and not df_multi.empty:\n",
    "    print(\"\\nüìã Die ersten 10 Teams aus allen Seiten:\")\n",
    "    print(df_multi.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374640ab",
   "metadata": {},
   "source": [
    "## Komplette Webscraping-Checkliste & Workflow\n",
    "Hier sind alle Aufgaben und der Workflow f√ºr das Hockey-Webscraping in einem Notebook vereint:\n",
    "\n",
    "1. CSV speichern\n",
    "2. CSV laden\n",
    "3. Letzte Seite erkennen\n",
    "4. Alle Seiten scrapen\n",
    "5. Daten analysieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492082a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CSV gespeichert als: hockey_teams_20251013_161957.csv\n",
      "üìÇ Geladene Daten:\n",
      "            Team Name  Year  Wins\n",
      "0       Boston Bruins  1990    44\n",
      "1  Chicago Blackhawks  1991    33\n",
      "üö© Letzte Seite erreicht!\n",
      "üö© Letzte Seite erreicht!\n",
      "‚úÖ Seite 1: 25 Teams\n",
      "‚úÖ Seite 1: 25 Teams\n",
      "‚úÖ Seite 2: 25 Teams\n",
      "‚úÖ Seite 2: 25 Teams\n",
      "‚úÖ Seite 3: 25 Teams\n",
      "‚úÖ Seite 3: 25 Teams\n",
      "üíæ Alle Teams gespeichert als: hockey_all_teams_20251013_162004.csv\n",
      "üìã Die ersten 10 Teams aus allen Seiten:\n",
      "               Team Name  Year Wins Losses OT Losses  Win % Goals For (GF)  \\\n",
      "0          Boston Bruins  1990   44     24      None   0.55            299   \n",
      "1         Buffalo Sabres  1990   31     30      None  0.388            292   \n",
      "2         Calgary Flames  1990   46     26      None  0.575            344   \n",
      "3     Chicago Blackhawks  1990   49     23      None  0.613            284   \n",
      "4      Detroit Red Wings  1990   34     38      None  0.425            273   \n",
      "5        Edmonton Oilers  1990   37     37      None  0.463            272   \n",
      "6       Hartford Whalers  1990   31     38      None  0.388            238   \n",
      "7      Los Angeles Kings  1990   46     24      None  0.575            340   \n",
      "8  Minnesota North Stars  1990   27     39      None  0.338            256   \n",
      "9     Montreal Canadiens  1990   39     30      None  0.487            273   \n",
      "\n",
      "  Goals Against (GA) + / -  \n",
      "0                264    35  \n",
      "1                278    14  \n",
      "2                263    81  \n",
      "3                211    73  \n",
      "4                298   -25  \n",
      "5                272     0  \n",
      "6                276   -38  \n",
      "7                254    86  \n",
      "8                266   -10  \n",
      "9                249    24  \n",
      "üíæ Alle Teams gespeichert als: hockey_all_teams_20251013_162004.csv\n",
      "üìã Die ersten 10 Teams aus allen Seiten:\n",
      "               Team Name  Year Wins Losses OT Losses  Win % Goals For (GF)  \\\n",
      "0          Boston Bruins  1990   44     24      None   0.55            299   \n",
      "1         Buffalo Sabres  1990   31     30      None  0.388            292   \n",
      "2         Calgary Flames  1990   46     26      None  0.575            344   \n",
      "3     Chicago Blackhawks  1990   49     23      None  0.613            284   \n",
      "4      Detroit Red Wings  1990   34     38      None  0.425            273   \n",
      "5        Edmonton Oilers  1990   37     37      None  0.463            272   \n",
      "6       Hartford Whalers  1990   31     38      None  0.388            238   \n",
      "7      Los Angeles Kings  1990   46     24      None  0.575            340   \n",
      "8  Minnesota North Stars  1990   27     39      None  0.338            256   \n",
      "9     Montreal Canadiens  1990   39     30      None  0.487            273   \n",
      "\n",
      "  Goals Against (GA) + / -  \n",
      "0                264    35  \n",
      "1                278    14  \n",
      "2                263    81  \n",
      "3                211    73  \n",
      "4                298   -25  \n",
      "5                272     0  \n",
      "6                276   -38  \n",
      "7                254    86  \n",
      "8                266   -10  \n",
      "9                249    24  \n"
     ]
    }
   ],
   "source": [
    "# 1. CSV speichern\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "data = {\n",
    "    'Team Name': ['Boston Bruins', 'Chicago Blackhawks'],\n",
    "    'Year': [1990, 1991],\n",
    "    'Wins': [44, 33]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "csv_filename = f'hockey_teams_{timestamp}.csv'\n",
    "df.to_csv(csv_filename, index=False)\n",
    "print(f'‚úÖ CSV gespeichert als: {csv_filename}')\n",
    "\n",
    "# 2. CSV laden\n",
    "df_loaded = pd.read_csv(csv_filename)\n",
    "print('üìÇ Geladene Daten:')\n",
    "print(df_loaded)\n",
    "\n",
    "# 3. Letzte Seite erkennen\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "def is_last_page(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table', class_='table')\n",
    "    if not table:\n",
    "        return True\n",
    "    teams = table.find_all('tr', class_='team')\n",
    "    return len(teams) == 0\n",
    "test_url = 'https://www.scrapethissite.com/pages/forms/?page_num=25'\n",
    "if is_last_page(test_url):\n",
    "    print('üö© Letzte Seite erreicht!')\n",
    "else:\n",
    "    print('‚û°Ô∏è Weitere Seiten vorhanden.')\n",
    "\n",
    "# 4. Alle Seiten scrapen\n",
    "import time\n",
    "def scrape_all_hockey_pages(max_pages=25, delay=1.0):\n",
    "    all_data = []\n",
    "    headers_list = []\n",
    "    for page in range(1, max_pages + 1):\n",
    "        url = f'https://www.scrapethissite.com/pages/forms/?page_num={page}'\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table', class_='table')\n",
    "        if not table:\n",
    "            print(f'‚ùå Keine Tabelle auf Seite {page}')\n",
    "            break\n",
    "        if page == 1:\n",
    "            headers_list = [th.get_text().strip() for th in table.find('tr').find_all('th')]\n",
    "        team_rows = table.find_all('tr', class_='team')\n",
    "        for row in team_rows:\n",
    "            row_data = [td.get_text().strip() or None for td in row.find_all('td')]\n",
    "            if len(row_data) == len(headers_list):\n",
    "                all_data.append(row_data)\n",
    "        print(f'‚úÖ Seite {page}: {len(team_rows)} Teams')\n",
    "        time.sleep(delay)\n",
    "    df_multi = pd.DataFrame(all_data, columns=headers_list)\n",
    "    return df_multi\n",
    "df_multi = scrape_all_hockey_pages(max_pages=25, delay=1.0)  # Zum Testen nur 3 Seiten\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "multi_csv_filename = f'hockey_all_teams_{timestamp}.csv'\n",
    "df_multi.to_csv(multi_csv_filename, index=False)\n",
    "print(f'üíæ Alle Teams gespeichert als: {multi_csv_filename}')\n",
    "\n",
    "# 5. Daten analysieren\n",
    "if not df_multi.empty:\n",
    "    print('üìã Die ersten 10 Teams aus allen Seiten:')\n",
    "    print(df_multi.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
